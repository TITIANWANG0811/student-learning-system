#!/usr/bin/env python3
"""
å¯¼å…¥åˆäºŒè‹±è¯­å•è¯åˆ°æ•°æ®åº“
"""
import os
import sys
import re
import uuid
from pathlib import Path

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('/Users/titianwang/Workspace/App/StudentLearningSystem/backend')

from sqlalchemy.orm import Session
from app.core.database import SessionLocal
from app.models.recitation import Recitation
from app.models.user import User
from app.models.subject import Subject

def parse_markdown_file(file_path):
    """è§£æMarkdownæ–‡ä»¶ï¼Œæå–å•è¯ä¿¡æ¯"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–å•è¯åç§°ï¼ˆä»æ–‡ä»¶åï¼‰
    word_name = Path(file_path).stem.split('.', 1)[1]  # å»æ‰æ•°å­—å‰ç¼€
    
    # æå–éŸ³æ ‡
    phonetic_pattern = r'\*\*éŸ³æ ‡\*\*: (.*?)(?:\n|$)'
    phonetic_match = re.search(phonetic_pattern, content)
    phonetic = phonetic_match.group(1).strip() if phonetic_match else ""
    
    # æå–è¯æ€§
    pos_pattern = r'\*\*è¯æ€§\*\*: (.*?)(?:\n|$)'
    pos_match = re.search(pos_pattern, content)
    pos = pos_match.group(1).strip() if pos_match else ""
    
    # æå–ä¸­æ–‡é‡Šä¹‰
    meaning_pattern = r'\*\*ä¸­æ–‡é‡Šä¹‰\*\*: (.*?)(?:\n|$)'
    meaning_match = re.search(meaning_pattern, content)
    meaning = meaning_match.group(1).strip() if meaning_match else ""
    
    # æå–ä¾‹å¥
    examples_pattern = r'> \[!note\] ä¾‹å¥\s*>\s*\n(.*?)(?=\n> \[!|\n##|\Z)'
    examples_match = re.search(examples_pattern, content, re.DOTALL)
    examples = ""
    if examples_match:
        examples_text = examples_match.group(1)
        # æ¸…ç†æ ¼å¼
        examples_text = re.sub(r'^>\s*', '', examples_text, flags=re.MULTILINE)
        examples_text = re.sub(r'^\d+\.\s*', '', examples_text, flags=re.MULTILINE)
        examples = examples_text.strip()
    
    # æå–è”æƒ³è®°å¿†
    memory_pattern = r'> \[!tip\] è”æƒ³è®°å¿†\s*>\s*\n(.*?)(?=\n> \[!|\n##|\Z)'
    memory_match = re.search(memory_pattern, content, re.DOTALL)
    memory = ""
    if memory_match:
        memory_text = memory_match.group(1)
        # æ¸…ç†æ ¼å¼
        memory_text = re.sub(r'^>\s*', '', memory_text, flags=re.MULTILINE)
        memory_text = re.sub(r'^\*\*([^*]+)\*\*ï¼š', r'**\1**ï¼š', memory_text, flags=re.MULTILINE)
        memory = memory_text.strip()
    
    # æå–ç›¸å…³è¯æ±‡
    related_pattern = r'> \[!abstract\] ç›¸å…³è¯æ±‡\s*>\s*\n(.*?)(?=\n> \[!|\n##|\Z)'
    related_match = re.search(related_pattern, content, re.DOTALL)
    related = ""
    if related_match:
        related_text = related_match.group(1)
        # æ¸…ç†æ ¼å¼
        related_text = re.sub(r'^>\s*', '', related_text, flags=re.MULTILINE)
        related = related_text.strip()
    
    # æ„å»ºå®Œæ•´å†…å®¹
    full_content = f"""# {word_name}

## å•è¯ä¿¡æ¯

> [!info] å•è¯åŸºæœ¬ä¿¡æ¯
> - **å•è¯**: {word_name}
> - **éŸ³æ ‡**: {phonetic}
> - **è¯æ€§**: {pos}
> - **ä¸­æ–‡é‡Šä¹‰**: {meaning}

## è¯¦ç»†å†…å®¹

> [!note] ä¾‹å¥
>
> {examples}

> [!tip] è”æƒ³è®°å¿†
>
> {memory}

> [!abstract] ç›¸å…³è¯æ±‡
> {related}
"""
    
    return {
        'word_name': word_name,
        'phonetic': phonetic,
        'pos': pos,
        'meaning': meaning,
        'examples': examples,
        'memory': memory,
        'related': related,
        'full_content': full_content
    }

def get_or_create_user_and_subject(db: Session):
    """è·å–æˆ–åˆ›å»ºç”¨æˆ·å’Œå­¦ç§‘"""
    # è·å–æˆ–åˆ›å»ºæµ‹è¯•ç”¨æˆ·
    user = db.query(User).filter(User.username == "test_student").first()
    if not user:
        user = User(
            id=uuid.uuid4(),
            username="test_student",
            email="test@example.com",
            full_name="æµ‹è¯•å­¦ç”Ÿ",
            grade="åˆäºŒ",
            is_active=True
        )
        db.add(user)
        db.commit()
        print("åˆ›å»ºäº†æµ‹è¯•ç”¨æˆ·")
    
    # è·å–æˆ–åˆ›å»ºè‹±è¯­å­¦ç§‘
    subject = db.query(Subject).filter(Subject.name == "è‹±è¯­").first()
    if not subject:
        subject = Subject(
            id=uuid.uuid4(),
            name="è‹±è¯­",
            code="english",
            description="è‹±è¯­å­¦ç§‘",
            color="#1890ff",
            icon="ğŸ“š",
            difficulty_level=2,
            is_core_subject=True,
            is_active=True
        )
        db.add(subject)
        db.commit()
        print("åˆ›å»ºäº†è‹±è¯­å­¦ç§‘")
    
    return user.id, subject.id

def import_grade2_english():
    """å¯¼å…¥åˆäºŒè‹±è¯­å•è¯"""
    # è®¾ç½®è·¯å¾„
    base_path = Path("/Users/titianwang/Workspace/Obsidian/work/å·¥ä½œ/01. ç”Ÿæ´»/02. å­å¥³æ•™è‚²/å°åˆä¸­è‹±è¯­/02. åˆäºŒ/01. ç”Ÿè¯è¡¨")
    
    # è·å–æ•°æ®åº“è¿æ¥
    db = SessionLocal()
    
    try:
        # è·å–ç”¨æˆ·å’Œå­¦ç§‘ID
        user_id, subject_id = get_or_create_user_and_subject(db)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_imported = 0
        total_skipped = 0
        
        # éå†æ‰€æœ‰å•å…ƒ
        for unit_dir in sorted(base_path.iterdir()):
            if unit_dir.is_dir() and unit_dir.name.startswith(('01', '02', '03', '04', '05', '06')):
                unit_name = unit_dir.name.split('.', 1)[1]  # å»æ‰æ•°å­—å‰ç¼€
                print(f"\nå¤„ç†å•å…ƒ: {unit_name}")
                
                # éå†å•å…ƒä¸­çš„æ‰€æœ‰å•è¯æ–‡ä»¶
                for word_file in sorted(unit_dir.glob("*.md")):
                    try:
                        # è§£ææ–‡ä»¶
                        word_data = parse_markdown_file(word_file)
                        word_name = word_data['word_name']
                        
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        existing = db.query(Recitation).filter(
                            Recitation.title == word_name,
                            Recitation.grade_level == "åˆäºŒ",
                            Recitation.unit_name == unit_name
                        ).first()
                        
                        if existing:
                            print(f"  è·³è¿‡å·²å­˜åœ¨çš„å•è¯: {word_name}")
                            total_skipped += 1
                            continue
                        
                        # ç¡®å®šè¯æ±‡ç±»å‹
                        vocabulary_type = "word"  # åˆäºŒè‹±è¯­å•è¯é»˜è®¤ä¸ºwordç±»å‹
                        
                        # åˆ›å»ºè®°å½•
                        recitation = Recitation(
                            id=uuid.uuid4(),
                            student_id=user_id,
                            subject_id=subject_id,
                            title=word_name,
                            content=word_data['full_content'],
                            markdown_content=word_data['full_content'],
                            recitation_type="vocabulary",
                            vocabulary_type=vocabulary_type,
                            grade_level="åˆäºŒ",
                            unit_name=unit_name,
                            difficulty_level=2,  # åˆäºŒéš¾åº¦
                            is_memorized=False,
                            practice_count=0
                        )
                        
                        db.add(recitation)
                        total_imported += 1
                        print(f"  å¯¼å…¥å•è¯: {word_name}")
                        
                    except Exception as e:
                        print(f"  å¤„ç†æ–‡ä»¶ {word_file.name} æ—¶å‡ºé”™: {e}")
                        continue
                
                # æäº¤å½“å‰å•å…ƒçš„æ•°æ®
                db.commit()
                print(f"  å•å…ƒ {unit_name} å¯¼å…¥å®Œæˆ")
        
        print(f"\nå¯¼å…¥å®Œæˆ!")
        print(f"æ€»å…±å¯¼å…¥: {total_imported} ä¸ªå•è¯")
        print(f"è·³è¿‡é‡å¤: {total_skipped} ä¸ªå•è¯")
        
    except Exception as e:
        print(f"å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    import_grade2_english()
